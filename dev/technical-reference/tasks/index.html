
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Determine the behaviour of your LLM by selecting a suitable task.">
      
      
        <meta name="author" content="Argilla, Inc.">
      
      
        <link rel="canonical" href="https://argilla-io.github.io/distilabel/dev/technical-reference/tasks/">
      
      
        <link rel="prev" href="../llms/">
      
      
        <link rel="next" href="../pipeline/">
      
      
      <link rel="icon" href="../../assets/logo.svg">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.6">
    
    
      
        <title>Tasks - distilabel</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.50c56a3b.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
      <link rel="stylesheet" href="../../css/ansi-colours.css">
    
      <link rel="stylesheet" href="../../css/jupyter-cells.css">
    
      <link rel="stylesheet" href="../../css/pandas-dataframe.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
      
        <meta  property="og:type"  content="website" >
      
        <meta  property="og:title"  content="Tasks - distilabel" >
      
        <meta  property="og:description"  content="Determine the behaviour of your LLM by selecting a suitable task." >
      
        <meta  property="og:image"  content="https://argilla-io.github.io/distilabel/dev/assets/images/social/technical-reference/tasks.png" >
      
        <meta  property="og:image:type"  content="image/png" >
      
        <meta  property="og:image:width"  content="1200" >
      
        <meta  property="og:image:height"  content="630" >
      
        <meta  property="og:url"  content="https://argilla-io.github.io/distilabel/dev/technical-reference/tasks/" >
      
        <meta  name="twitter:card"  content="summary_large_image" >
      
        <meta  name="twitter:title"  content="Tasks - distilabel" >
      
        <meta  name="twitter:description"  content="Determine the behaviour of your LLM by selecting a suitable task." >
      
        <meta  name="twitter:image"  content="https://argilla-io.github.io/distilabel/dev/assets/images/social/technical-reference/tasks.png" >
      
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#tasks" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="distilabel" class="md-header__button md-logo" aria-label="distilabel" data-md-component="logo">
      
  <img src="../../assets/logo.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            distilabel
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Tasks
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="custom" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/argilla-io/distilabel" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    argilla-io/distilabel
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
    
  
  Getting started

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../concepts/" class="md-tabs__link">
        
  
    
  
  Concepts

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../tutorials/pipeline-notus-instructions-preferences-legal/" class="md-tabs__link">
          
  
  Tutorials

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  Technical References

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="distilabel" class="md-nav__button md-logo" aria-label="distilabel" data-md-component="logo">
      
  <img src="../../assets/logo.svg" alt="logo">

    </a>
    distilabel
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/argilla-io/distilabel" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    argilla-io/distilabel
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting started
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../concepts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Concepts
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Tutorials
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/pipeline-notus-instructions-preferences-legal/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ⚖️ Create a legal preference dataset
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/clean-preference-dataset-judgelm-gpt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    🧼 Clean an existing preference dataset
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/create-a-math-preference-dataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    🧮 Create a mathematical preference dataset
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Technical References
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Technical References
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Concept Guides
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4_1">
            <span class="md-nav__icon md-icon"></span>
            Concept Guides
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LLMs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Tasks
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Tasks
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#task" class="md-nav__link">
    <span class="md-ellipsis">
      Task
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-generation" class="md-nav__link">
    <span class="md-ellipsis">
      Text Generation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Text Generation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#textgenerationtask" class="md-nav__link">
    <span class="md-ellipsis">
      TextGenerationTask
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#selfinstructtask" class="md-nav__link">
    <span class="md-ellipsis">
      SelfInstructTask
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SelfInstructTask">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#customise-your-selfinstructtask" class="md-nav__link">
    <span class="md-ellipsis">
      Customise your SelfInstructTask
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evolinstructtask" class="md-nav__link">
    <span class="md-ellipsis">
      EvolInstructTask
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#labelling" class="md-nav__link">
    <span class="md-ellipsis">
      Labelling
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Labelling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#preference" class="md-nav__link">
    <span class="md-ellipsis">
      Preference
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Preference">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ultrafeedbacktask" class="md-nav__link">
    <span class="md-ellipsis">
      UltraFeedbackTask
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#judgelmtask" class="md-nav__link">
    <span class="md-ellipsis">
      JudgeLMTask
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ultrajudgetask" class="md-nav__link">
    <span class="md-ellipsis">
      UltraJudgeTask
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#complexityscorertask" class="md-nav__link">
    <span class="md-ellipsis">
      ComplexityScorerTask
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qualityscorertask" class="md-nav__link">
    <span class="md-ellipsis">
      QualityScorerTask
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#critique" class="md-nav__link">
    <span class="md-ellipsis">
      Critique
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Critique">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ultracmtask" class="md-nav__link">
    <span class="md-ellipsis">
      UltraCMTask
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prometheustask" class="md-nav__link">
    <span class="md-ellipsis">
      PrometheusTask
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pipelines
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2" >
        
          
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    API Reference
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            API Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2_1" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../reference/distilabel/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    distilabel
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_2_1" id="__nav_4_2_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2_1">
            <span class="md-nav__icon md-icon"></span>
            distilabel
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/dataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    dataset
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2_1_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../reference/distilabel/llm/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    llm
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_2_1_2" id="__nav_4_2_1_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_4_2_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2_1_2">
            <span class="md-nav__icon md-icon"></span>
            llm
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/llm/anyscale/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    anyscale
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/llm/base/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    base
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2_1_2_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../reference/distilabel/llm/google/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    google
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_2_1_2_3" id="__nav_4_2_1_2_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="5" aria-labelledby="__nav_4_2_1_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2_1_2_3">
            <span class="md-nav__icon md-icon"></span>
            google
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/llm/google/vertexai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    vertexai
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2_1_2_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../reference/distilabel/llm/huggingface/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    huggingface
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_2_1_2_4" id="__nav_4_2_1_2_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="5" aria-labelledby="__nav_4_2_1_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2_1_2_4">
            <span class="md-nav__icon md-icon"></span>
            huggingface
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/llm/huggingface/inference_endpoints/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    inference_endpoints
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/llm/huggingface/transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    transformers
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/llm/llama_cpp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama_cpp
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/llm/ollama/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ollama
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/llm/openai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    openai
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/llm/together/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    together
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/llm/utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    utils
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/llm/vllm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    vllm
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/logger/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    logger
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/pipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pipeline
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/progress_bar/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    progress_bar
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2_1_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../reference/distilabel/tasks/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    tasks
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_2_1_6" id="__nav_4_2_1_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_4_2_1_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2_1_6">
            <span class="md-nav__icon md-icon"></span>
            tasks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/tasks/base/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    base
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2_1_6_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../reference/distilabel/tasks/critique/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    critique
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_2_1_6_2" id="__nav_4_2_1_6_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="5" aria-labelledby="__nav_4_2_1_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2_1_6_2">
            <span class="md-nav__icon md-icon"></span>
            critique
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/tasks/critique/base/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    base
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/tasks/critique/prometheus/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    prometheus
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/tasks/critique/ultracm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ultracm
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/tasks/mixins/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mixins
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2_1_6_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../reference/distilabel/tasks/preference/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    preference
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_2_1_6_4" id="__nav_4_2_1_6_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="5" aria-labelledby="__nav_4_2_1_6_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2_1_6_4">
            <span class="md-nav__icon md-icon"></span>
            preference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/tasks/preference/base/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    base
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/tasks/preference/complexity_scorer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    complexity_scorer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/tasks/preference/judgelm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    judgelm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/tasks/preference/quality_scorer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    quality_scorer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/tasks/preference/ultrafeedback/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ultrafeedback
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/tasks/preference/ultrajudge/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ultrajudge
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/tasks/prompt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    prompt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2_1_6_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../reference/distilabel/tasks/text_generation/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    text_generation
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_2_1_6_6" id="__nav_4_2_1_6_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="5" aria-labelledby="__nav_4_2_1_6_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2_1_6_6">
            <span class="md-nav__icon md-icon"></span>
            text_generation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/tasks/text_generation/base/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    base
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/tasks/text_generation/evol_instruct/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    evol_instruct
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/tasks/text_generation/mixins/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mixins
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/tasks/text_generation/principles/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    principles
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/tasks/text_generation/self_instruct/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    self_instruct
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2_1_7" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../reference/distilabel/utils/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    utils
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_2_1_7" id="__nav_4_2_1_7_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_4_2_1_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2_1_7">
            <span class="md-nav__icon md-icon"></span>
            utils
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/utils/argilla/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    argilla
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/utils/dataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    dataset
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/utils/dicts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    dicts
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/utils/futures/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    futures
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/utils/imports/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    imports
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/utils/serialization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    serialization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/distilabel/utils/types/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    types
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#task" class="md-nav__link">
    <span class="md-ellipsis">
      Task
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-generation" class="md-nav__link">
    <span class="md-ellipsis">
      Text Generation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Text Generation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#textgenerationtask" class="md-nav__link">
    <span class="md-ellipsis">
      TextGenerationTask
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#selfinstructtask" class="md-nav__link">
    <span class="md-ellipsis">
      SelfInstructTask
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SelfInstructTask">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#customise-your-selfinstructtask" class="md-nav__link">
    <span class="md-ellipsis">
      Customise your SelfInstructTask
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evolinstructtask" class="md-nav__link">
    <span class="md-ellipsis">
      EvolInstructTask
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#labelling" class="md-nav__link">
    <span class="md-ellipsis">
      Labelling
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Labelling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#preference" class="md-nav__link">
    <span class="md-ellipsis">
      Preference
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Preference">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ultrafeedbacktask" class="md-nav__link">
    <span class="md-ellipsis">
      UltraFeedbackTask
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#judgelmtask" class="md-nav__link">
    <span class="md-ellipsis">
      JudgeLMTask
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ultrajudgetask" class="md-nav__link">
    <span class="md-ellipsis">
      UltraJudgeTask
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#complexityscorertask" class="md-nav__link">
    <span class="md-ellipsis">
      ComplexityScorerTask
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qualityscorertask" class="md-nav__link">
    <span class="md-ellipsis">
      QualityScorerTask
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#critique" class="md-nav__link">
    <span class="md-ellipsis">
      Critique
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Critique">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ultracmtask" class="md-nav__link">
    <span class="md-ellipsis">
      UltraCMTask
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prometheustask" class="md-nav__link">
    <span class="md-ellipsis">
      PrometheusTask
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="tasks">Tasks<a class="headerlink" href="#tasks" title="Permanent link">&para;</a></h1>
<p>In this section we will see what's a <code>Task</code> and the list of tasks available in <code>distilabel</code>.</p>
<h2 id="task">Task<a class="headerlink" href="#task" title="Permanent link">&para;</a></h2>
<p>The <code>Task</code> class takes charge of setting how the LLM behaves, deciding whether it acts as a <em>generator</em> or a <em>labeller</em>. To accomplish this, the <code>Task</code> class creates a prompt using a template that will be sent to the <a href="../llms/"><code>LLM</code></a>. It specifies the necessary input arguments for generating the prompt and identifies the output arguments to be extracted from the <code>LLM</code> response. The <code>Task</code> class yields a <code>Prompt</code> that can generate a string with the format needed, depending on the specific <code>LLM</code> used.</p>
<p>All the <code>Task</code>s defines a <code>system_prompt</code> which serves as the initial instruction given to the LLM, guiding it on what kind of information or output is expected, and the following methods:</p>
<ul>
<li><code>generate_prompt</code>: This method will be used by the <code>LLM</code> to create the prompts that will be fed to the model.</li>
<li><code>parse_output</code>: After the <code>LLM</code> has generated the content, this method will be called on the raw outputs of the model to extract the relevant content (scores, rationales, etc).</li>
<li><code>input_args_names</code> and <code>output_args_names</code>: These methods are used in the <a href="../pipeline/"><code>Pipeline</code></a> to process the datasets. The first one defines the columns that will be extracted from the dataset to build the prompt in case of a <code>LLM</code> that acts as a generator or labeller alone, or the columns that should be placed in the dataset to be processed by the <em>labeller</em> <code>LLM</code>, in the case of a <code>Pipeline</code> that has both a <em>generator</em> and a <em>labeller</em>. The second one is in charge of inserting the defined fields as columns of the dataset generated dataset.</li>
</ul>
<p>After defining a task, the only action required is to pass it to the corresponding <code>LLM</code>. All the intricate processes are then handled internally:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="kn">from</span> <span class="nn">distilabel.llm</span> <span class="kn">import</span> <span class="n">TransformersLLM</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="kn">from</span> <span class="nn">distilabel.tasks</span> <span class="kn">import</span> <span class="n">TextGenerationTask</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="c1"># This snippet uses `TransformersLLM`, but is the same for every other `LLM`.</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="n">generator</span> <span class="o">=</span> <span class="n">TransformersLLM</span><span class="p">(</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">model</span><span class="o">=...</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">tokenizer</span><span class="o">=...</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n">task</span><span class="o">=</span><span class="n">TextGenerationTask</span><span class="p">(),</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="p">)</span>
</span></code></pre></div>
<p>Given this explanation, <code>distilabel</code> distinguishes between two primary categories of tasks: those focused on text generation and those centered around labelling. These <code>Task</code> classes delineate the LLM's conduct, be it the creation of textual content or the assignment of labels to text, each with precise guidelines tailored to their respective functionalities. Users can seamlessly leverage these distinct task types to tailor the LLM's behavior according to their specific application needs.</p>
<h2 id="text-generation">Text Generation<a class="headerlink" href="#text-generation" title="Permanent link">&para;</a></h2>
<p>These set of classes are designed to steer a <code>LLM</code> in generating text with specific guidelines. They provide a structured approach to instruct the LLM on generating content in a manner tailored to predefined criteria.</p>
<h3 id="textgenerationtask">TextGenerationTask<a class="headerlink" href="#textgenerationtask" title="Permanent link">&para;</a></h3>
<p>This is the base class for <em>text generation</em>, and includes the following fields for guiding the generation process:</p>
<ul>
<li><code>system_prompt</code>, which serves as the initial instruction or query given to the LLM, guiding it on what kind of information or output is expected.</li>
<li>A list of <code>principles</code> to inject on the <code>system_prompt</code>, which by default correspond to those defined in the UltraFeedback paper<sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup>,</li>
<li>and lastly a distribution for these principles so the <code>LLM</code> can be directed towards the different principles with a more customized behaviour.</li>
</ul>
<p>For the API reference visit <a class="autorefs autorefs-internal" href="../../reference/distilabel/tasks/text_generation/base/#distilabel.tasks.text_generation.base.TextGenerationTask">TextGenerationTask</a>.</p>
<h3 id="selfinstructtask">SelfInstructTask<a class="headerlink" href="#selfinstructtask" title="Permanent link">&para;</a></h3>
<p>The task specially designed to build the prompts following the Self-Instruct paper: <a href="https://arxiv.org/abs/2212.10560">SELF-INSTRUCT: Aligning Language Models
with Self-Generated Instructions</a>.</p>
<p>From the original <a href="https://github.com/yizhongw/self-instruct/tree/main#how-self-instruct-works">repository</a>:</p>
<p><em>The Self-Instruct process is an iterative bootstrapping algorithm that starts with a seed set of manually-written instructions and uses them to prompt the language model to generate new instructions and corresponding input-output instances</em>, so this <code>Task</code> is specially interesting for generating new datasets from a set of predefined topics.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="kn">import</span> <span class="nn">os</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="kn">from</span> <span class="nn">distilabel.llm</span> <span class="kn">import</span> <span class="n">OpenAILLM</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a><span class="kn">from</span> <span class="nn">distilabel.tasks</span> <span class="kn">import</span> <span class="n">SelfInstructTask</span>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a><span class="n">generator</span> <span class="o">=</span> <span class="n">OpenAILLM</span><span class="p">(</span>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>    <span class="n">task</span><span class="o">=</span><span class="n">SelfInstructTask</span><span class="p">(</span>
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>        <span class="n">system_prompt</span><span class="o">=</span><span class="s2">&quot;You are a question-answering assistant for...&quot;</span><span class="p">,</span>
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a>        <span class="n">application_description</span><span class="o">=</span><span class="s2">&quot;AI assistant&quot;</span><span class="p">,</span>
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a>        <span class="n">num_instructions</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
</span><span id="__span-1-11"><a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a>        <span class="n">criteria_for_query_generation</span><span class="o">=</span><span class="s2">&quot;Design queries to be... &quot;</span><span class="p">,</span>
</span><span id="__span-1-12"><a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a>    <span class="p">),</span>
</span><span id="__span-1-13"><a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a>    <span class="n">openai_api_key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">),</span>
</span><span id="__span-1-14"><a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a><span class="p">)</span>
</span></code></pre></div>
<p>For the API reference visit <a class="autorefs autorefs-internal" href="../../reference/distilabel/tasks/text_generation/self_instruct/#distilabel.tasks.text_generation.self_instruct.SelfInstructTask">SelfInstructTask</a>.</p>
<h4 id="customise-your-selfinstructtask">Customise your SelfInstructTask<a class="headerlink" href="#customise-your-selfinstructtask" title="Permanent link">&para;</a></h4>
<p>You can personalize the way in which your SelfInstructTask behaves by changing the default values of the parameters to something that suits your use case. Let's go through them:</p>
<ul>
<li><strong>System Prompt</strong>: you can control the overall behaviour and expectations of your model.</li>
<li><strong>Application Description</strong>: a description of the AI application. By default, we use "AI Assistant".</li>
<li><strong>Number of instructions</strong>: number of instructions in the prompt.</li>
<li><strong>Criteria for Query Generation</strong>: the criteria for query generation that we want our model to have. The default value covers default behaviour for SelfInstructTask. This value is passed to the .jinja template, where extra instructions are added to ensure correct output format.</li>
</ul>
<p>Let's see an example of how to customise a SelfInstructTask to create Haikus in the snippet below. You can take a look at this dataset as an example of a <a href="https://huggingface.co/datasets/davanstrien/haiku_dpo">Haiku DPO dataset</a>.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="kn">from</span> <span class="nn">distilabel.tasks</span> <span class="kn">import</span> <span class="n">SelfInstructTask</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;You are an expert Haiku writer, writing the best and most diverse Haikus given topics as inputs.&quot;</span>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="n">application_description</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>    <span class="s2">&quot;An AI assistant adept at writing Haiku.</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a>    <span class="s2">&quot;It expects complete suggestions from users providing details of the kind of haiku they want.</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="__span-2-8"><a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a>    <span class="s2">&quot;The AI assistant will help users write haiku about particular topics and is willing to accept requests related to a specific subject or object or a more abstract request&quot;</span>
</span><span id="__span-2-9"><a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a>    <span class="s2">&quot;based on an emotion, theme or vibe.</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="__span-2-10"><a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a><span class="p">)</span>
</span><span id="__span-2-11"><a id="__codelineno-2-11" name="__codelineno-2-11" href="#__codelineno-2-11"></a>
</span><span id="__span-2-12"><a id="__codelineno-2-12" name="__codelineno-2-12" href="#__codelineno-2-12"></a>
</span><span id="__span-2-13"><a id="__codelineno-2-13" name="__codelineno-2-13" href="#__codelineno-2-13"></a><span class="n">criteria_queries</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-2-14"><a id="__codelineno-2-14" name="__codelineno-2-14" href="#__codelineno-2-14"></a>    <span class="s2">&quot;Incorporate a diverse range of verbs, avoiding repetition.</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="__span-2-15"><a id="__codelineno-2-15" name="__codelineno-2-15" href="#__codelineno-2-15"></a>    <span class="s2">&quot;Ensure queries are compatible with AI model&#39;s text generation functions and are limited to 1-2 sentences.</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="__span-2-16"><a id="__codelineno-2-16" name="__codelineno-2-16" href="#__codelineno-2-16"></a>    <span class="s2">&quot;Design queries to be self-contained and standalone.&quot;</span>
</span><span id="__span-2-17"><a id="__codelineno-2-17" name="__codelineno-2-17" href="#__codelineno-2-17"></a><span class="p">)</span>
</span><span id="__span-2-18"><a id="__codelineno-2-18" name="__codelineno-2-18" href="#__codelineno-2-18"></a>
</span><span id="__span-2-19"><a id="__codelineno-2-19" name="__codelineno-2-19" href="#__codelineno-2-19"></a><span class="n">instruction_task</span> <span class="o">=</span> <span class="n">SelfInstructTask</span><span class="p">(</span>
</span><span id="__span-2-20"><a id="__codelineno-2-20" name="__codelineno-2-20" href="#__codelineno-2-20"></a>    <span class="n">num_instructions</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
</span><span id="__span-2-21"><a id="__codelineno-2-21" name="__codelineno-2-21" href="#__codelineno-2-21"></a>    <span class="n">application_description</span><span class="o">=</span><span class="n">application_description</span><span class="p">,</span>
</span><span id="__span-2-22"><a id="__codelineno-2-22" name="__codelineno-2-22" href="#__codelineno-2-22"></a>    <span class="n">criteria_for_query_generation</span><span class="o">=</span><span class="n">criteria_queries</span><span class="p">,</span>
</span><span id="__span-2-23"><a id="__codelineno-2-23" name="__codelineno-2-23" href="#__codelineno-2-23"></a><span class="p">)</span>
</span><span id="__span-2-24"><a id="__codelineno-2-24" name="__codelineno-2-24" href="#__codelineno-2-24"></a>
</span><span id="__span-2-25"><a id="__codelineno-2-25" name="__codelineno-2-25" href="#__codelineno-2-25"></a><span class="c1"># Let&#39;s print the generated prompt to see the input of the LLM model</span>
</span><span id="__span-2-26"><a id="__codelineno-2-26" name="__codelineno-2-26" href="#__codelineno-2-26"></a><span class="nb">print</span><span class="p">(</span><span class="n">instruction_task</span><span class="o">.</span><span class="n">generate_prompt</span><span class="p">(</span><span class="s2">&quot;mountain peaks&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">formatted_prompt</span><span class="p">)</span>
</span><span id="__span-2-27"><a id="__codelineno-2-27" name="__codelineno-2-27" href="#__codelineno-2-27"></a>
</span><span id="__span-2-28"><a id="__codelineno-2-28" name="__codelineno-2-28" href="#__codelineno-2-28"></a><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-2-29"><a id="__codelineno-2-29" name="__codelineno-2-29" href="#__codelineno-2-29"></a><span class="sd"># Task Description</span>
</span><span id="__span-2-30"><a id="__codelineno-2-30" name="__codelineno-2-30" href="#__codelineno-2-30"></a><span class="sd">Develop 15 user queries that can be received by the given AI application and applicable to the provided context. Emphasize diversity in verbs and linguistic structures within the model’s textual capabilities.</span>
</span><span id="__span-2-31"><a id="__codelineno-2-31" name="__codelineno-2-31" href="#__codelineno-2-31"></a><span class="sd"># Criteria for Queries</span>
</span><span id="__span-2-32"><a id="__codelineno-2-32" name="__codelineno-2-32" href="#__codelineno-2-32"></a><span class="sd">Incorporate a diverse range of verbs, avoiding repetition.</span>
</span><span id="__span-2-33"><a id="__codelineno-2-33" name="__codelineno-2-33" href="#__codelineno-2-33"></a><span class="sd">Ensure queries are compatible with AI model’s text generation functions and are limited to 1-2 sentences.</span>
</span><span id="__span-2-34"><a id="__codelineno-2-34" name="__codelineno-2-34" href="#__codelineno-2-34"></a><span class="sd">Design queries to be self-contained and standalone.</span>
</span><span id="__span-2-35"><a id="__codelineno-2-35" name="__codelineno-2-35" href="#__codelineno-2-35"></a><span class="sd">Write each query on a separate line and avoid using numbered lists or bullet points.</span>
</span><span id="__span-2-36"><a id="__codelineno-2-36" name="__codelineno-2-36" href="#__codelineno-2-36"></a><span class="sd"># AI Application</span>
</span><span id="__span-2-37"><a id="__codelineno-2-37" name="__codelineno-2-37" href="#__codelineno-2-37"></a><span class="sd">An AI assistant adept at writing Haiku.</span>
</span><span id="__span-2-38"><a id="__codelineno-2-38" name="__codelineno-2-38" href="#__codelineno-2-38"></a><span class="sd">It expects complete suggestions from users providing details of the kind of haiku they want.</span>
</span><span id="__span-2-39"><a id="__codelineno-2-39" name="__codelineno-2-39" href="#__codelineno-2-39"></a><span class="sd">The AI assistant will help users write haiku about particular topics and is willing to accept requests related to a specific subject or object or a more abstract requestbased on an emotion, theme or vibe.</span>
</span><span id="__span-2-40"><a id="__codelineno-2-40" name="__codelineno-2-40" href="#__codelineno-2-40"></a><span class="sd"># Context</span>
</span><span id="__span-2-41"><a id="__codelineno-2-41" name="__codelineno-2-41" href="#__codelineno-2-41"></a><span class="sd">mountain peaks</span>
</span><span id="__span-2-42"><a id="__codelineno-2-42" name="__codelineno-2-42" href="#__codelineno-2-42"></a><span class="sd"># Output</span>
</span><span id="__span-2-43"><a id="__codelineno-2-43" name="__codelineno-2-43" href="#__codelineno-2-43"></a><span class="sd">&quot;&quot;&quot;</span>
</span></code></pre></div>
<h3 id="evolinstructtask">EvolInstructTask<a class="headerlink" href="#evolinstructtask" title="Permanent link">&para;</a></h3>
<p>The task is specially designed to build the prompts following the Evol-Instruct strategy proposed in: <a href="https://arxiv.org/abs/2304.12244">WizardLM: Empowering Large Language Models to
Follow Complex Instructions</a>.</p>
<p>From the original <a href="https://github.com/nlpxucan/WizardLM/tree/main?tab=readme-ov-file#overview-of-evol-instruct">repository</a>:</p>
<p><em>Evol-Instruct is a novel method using LLMs instead of humans to automatically mass-produce open-domain instructions of various difficulty levels and skill range, to improve the performance of LLMs</em>.</p>
<p>Use this <code>Task</code> to build more complete and complex datasets starting from simple ones.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="kn">import</span> <span class="nn">os</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a><span class="kn">from</span> <span class="nn">distilabel.llm</span> <span class="kn">import</span> <span class="n">OpenAILLM</span>
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a><span class="kn">from</span> <span class="nn">distilabel.tasks</span> <span class="kn">import</span> <span class="n">EvolInstructTask</span>
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a><span class="n">generator</span> <span class="o">=</span> <span class="n">OpenAILLM</span><span class="p">(</span>
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>    <span class="n">task</span><span class="o">=</span><span class="n">EvolInstructTask</span><span class="p">(),</span>
</span><span id="__span-3-8"><a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a>    <span class="n">openai_api_key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">),</span>
</span><span id="__span-3-9"><a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a><span class="p">)</span>
</span></code></pre></div>
<p>You can take a look at a <a href="https://huggingface.co/datasets/argilla/distilabel-sample-evol-instruct?row=19">sample dataset</a> generated using the script the following script: <a href="../../examples/pipeline-evol-instruct-alpaca.py">examples/pipeline-evol-instruct-alpaca.py</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
</div>
<p>The original definition of <code>EvolInstruct</code> considers an elimination evolving step with different
situations to remove the responses considered failures. Section 3.2, <em>Elimination Evolving</em> in <a href="https://arxiv.org/abs/2304.12244">WizardLM paper</a> shows these steps. We have implemented steps 2-4 as part of this task, but not step one. Step 1 of the elimination process can be implemented using labellers in <code>distilabel</code>, an example implementation can be found in the following script: <a href="../../examples/pipeline-openai-wizardl-equal-prompts.py">examples/pipeline-openai-wizardl-equal-prompts.py</a>.</p>
<p>For the API reference visit <a class="autorefs autorefs-internal" href="../../reference/distilabel/tasks/text_generation/evol_instruct/#distilabel.tasks.text_generation.evol_instruct.EvolInstructTask">EvolInstructTask</a>.</p>
<h2 id="labelling">Labelling<a class="headerlink" href="#labelling" title="Permanent link">&para;</a></h2>
<p>Instead of generating text, you can instruct the <code>LLM</code> to label datasets. The existing tasks are designed specifically for creating both <code>PreferenceTask</code> and <code>CritiqueTask</code> datasets.</p>
<h3 id="preference">Preference<a class="headerlink" href="#preference" title="Permanent link">&para;</a></h3>
<p>Preference datasets for Language Models (LLMs) are sets of information that show how people rank or prefer one thing over another in a straightforward and clear manner. These datasets help train language models to understand and generate content that aligns with user preferences, enhancing the model's ability to generate contextually relevant and preferred outputs.</p>
<p>Contrary to the <code>TextGenerationTask</code>, the <code>PreferenceTask</code> is not intended for direct use. It implements the default methods <code>input_args_names</code> and <code>output_args_names</code>, but <code>generate_prompt</code> and <code>parse_output</code> are specific to each <code>PreferenceTask</code>. Examining the <code>output_args_names</code> reveals that the generation will encompass both the rating and the rationale that influenced that rating.</p>
<h4 id="ultrafeedbacktask">UltraFeedbackTask<a class="headerlink" href="#ultrafeedbacktask" title="Permanent link">&para;</a></h4>
<p>This task is specifically designed to build the prompts following the format defined in the <a href="https://arxiv.org/abs/2310.01377">"UltraFeedback: Boosting Language Models With High Quality Feedback"</a> paper.</p>
<p>From the original <a href="https://github.com/OpenBMB/UltraFeedback">repository</a>: <em>To collect high-quality preference and textual feedback, we design a fine-grained annotation instruction, which contains 4 different aspects, namely instruction-following, truthfulness, honesty and helpfulness</em>. This <code>Task</code> is designed to label datasets following the different aspects defined for the UltraFeedback dataset creation.</p>
<p>The following snippet can be used as a simplified UltraFeedback Task, for which we define 3 different ratings, but take into account the predefined versions are intended to be used out of the box:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="kn">from</span> <span class="nn">textwrap</span> <span class="kn">import</span> <span class="n">dedent</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a><span class="kn">from</span> <span class="nn">distilabel.tasks.preference.ultrafeedback</span> <span class="kn">import</span> <span class="n">Rating</span><span class="p">,</span> <span class="n">UltraFeedbackTask</span>
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a>
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a><span class="n">task_description</span> <span class="o">=</span> <span class="n">dedent</span><span class="p">(</span>
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-4-7"><a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a><span class="sd">    # General Text Quality Assessment</span>
</span><span id="__span-4-8"><a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a><span class="sd">    Evaluate the model&#39;s outputs based on various criteria:</span>
</span><span id="__span-4-9"><a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a><span class="sd">    1. **Correctness &amp; Informativeness**: Does the output provide accurate and helpful information?</span>
</span><span id="__span-4-10"><a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a><span class="sd">    2. **Honesty &amp; Uncertainty**: How confidently does the model convey its information, and does it express uncertainty appropriately?</span>
</span><span id="__span-4-11"><a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a><span class="sd">    3. **Truthfulness &amp; Hallucination**: Does the model introduce misleading or fabricated details?</span>
</span><span id="__span-4-12"><a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a><span class="sd">    4. **Instruction Following**: Does the model&#39;s output align with given instructions and the user&#39;s intent?</span>
</span><span id="__span-4-13"><a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a><span class="sd">    Your role is to provide a holistic assessment considering all the above factors.</span>
</span><span id="__span-4-14"><a id="__codelineno-4-14" name="__codelineno-4-14" href="#__codelineno-4-14"></a>
</span><span id="__span-4-15"><a id="__codelineno-4-15" name="__codelineno-4-15" href="#__codelineno-4-15"></a><span class="sd">    **Scoring**: Rate outputs 1 to 3 based on the overall quality, considering all aspects:</span>
</span><span id="__span-4-16"><a id="__codelineno-4-16" name="__codelineno-4-16" href="#__codelineno-4-16"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-4-17"><a id="__codelineno-4-17" name="__codelineno-4-17" href="#__codelineno-4-17"></a><span class="p">)</span>
</span><span id="__span-4-18"><a id="__codelineno-4-18" name="__codelineno-4-18" href="#__codelineno-4-18"></a>
</span><span id="__span-4-19"><a id="__codelineno-4-19" name="__codelineno-4-19" href="#__codelineno-4-19"></a><span class="n">ratings</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-4-20"><a id="__codelineno-4-20" name="__codelineno-4-20" href="#__codelineno-4-20"></a>    <span class="n">Rating</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Low Quality&quot;</span><span class="p">),</span>
</span><span id="__span-4-21"><a id="__codelineno-4-21" name="__codelineno-4-21" href="#__codelineno-4-21"></a>    <span class="n">Rating</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Moderate Quality&quot;</span><span class="p">),</span>
</span><span id="__span-4-22"><a id="__codelineno-4-22" name="__codelineno-4-22" href="#__codelineno-4-22"></a>    <span class="n">Rating</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Good Quality&quot;</span><span class="p">),</span>
</span><span id="__span-4-23"><a id="__codelineno-4-23" name="__codelineno-4-23" href="#__codelineno-4-23"></a><span class="p">]</span>
</span><span id="__span-4-24"><a id="__codelineno-4-24" name="__codelineno-4-24" href="#__codelineno-4-24"></a>
</span><span id="__span-4-25"><a id="__codelineno-4-25" name="__codelineno-4-25" href="#__codelineno-4-25"></a><span class="n">ultrafeedback_task</span> <span class="o">=</span> <span class="n">UltraFeedbackTask</span><span class="p">(</span>
</span><span id="__span-4-26"><a id="__codelineno-4-26" name="__codelineno-4-26" href="#__codelineno-4-26"></a>    <span class="n">system_prompt</span><span class="o">=</span><span class="s2">&quot;Your role is to evaluate text quality based on given criteria&quot;</span><span class="p">,</span>
</span><span id="__span-4-27"><a id="__codelineno-4-27" name="__codelineno-4-27" href="#__codelineno-4-27"></a>    <span class="n">task_description</span><span class="o">=</span><span class="n">task_description</span><span class="p">,</span>
</span><span id="__span-4-28"><a id="__codelineno-4-28" name="__codelineno-4-28" href="#__codelineno-4-28"></a>    <span class="n">ratings</span><span class="o">=</span><span class="n">ratings</span><span class="p">,</span>
</span><span id="__span-4-29"><a id="__codelineno-4-29" name="__codelineno-4-29" href="#__codelineno-4-29"></a><span class="p">)</span>
</span></code></pre></div>
<div class="tabbed-set tabbed-alternate" data-tabs="1:4"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio" /><input id="__tabbed_1_2" name="__tabbed_1" type="radio" /><input id="__tabbed_1_3" name="__tabbed_1" type="radio" /><input id="__tabbed_1_4" name="__tabbed_1" type="radio" /><div class="tabbed-labels"><label for="__tabbed_1_1">Helpfulness</label><label for="__tabbed_1_2">Truthfulness</label><label for="__tabbed_1_3">Honesty</label><label for="__tabbed_1_4">Instruction Following</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>The following example creates a UltraFeedback task to emphasize helpfulness, that is overall quality and correctness of the output:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="kn">import</span> <span class="nn">os</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a><span class="kn">from</span> <span class="nn">distilabel.llm</span> <span class="kn">import</span> <span class="n">OpenAILLM</span>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a><span class="kn">from</span> <span class="nn">distilabel.tasks</span> <span class="kn">import</span> <span class="n">UltraFeedbackTask</span>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a><span class="n">labeller</span> <span class="o">=</span> <span class="n">OpenAILLM</span><span class="p">(</span>
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>    <span class="n">task</span><span class="o">=</span><span class="n">UltraFeedbackTask</span><span class="o">.</span><span class="n">for_helpfulness</span><span class="p">(),</span> <span class="n">openai_api_key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">)</span>
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a><span class="p">)</span>
</span></code></pre></div>
</div>
<div class="tabbed-block">
<p>The following example creates a UltraFeedback task to emphasize truthfulness and hallucination assessment:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="kn">import</span> <span class="nn">os</span>
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a><span class="kn">from</span> <span class="nn">distilabel.llm</span> <span class="kn">import</span> <span class="n">OpenAILLM</span>
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a><span class="kn">from</span> <span class="nn">distilabel.tasks</span> <span class="kn">import</span> <span class="n">UltraFeedbackTask</span>
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a>
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a><span class="n">labeller</span> <span class="o">=</span> <span class="n">OpenAILLM</span><span class="p">(</span>
</span><span id="__span-6-7"><a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a>    <span class="n">task</span><span class="o">=</span><span class="n">UltraFeedbackTask</span><span class="o">.</span><span class="n">for_truthfulness</span><span class="p">(),</span>
</span><span id="__span-6-8"><a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a>    <span class="n">openai_api_key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">),</span>
</span><span id="__span-6-9"><a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a><span class="p">)</span>
</span></code></pre></div>
</div>
<div class="tabbed-block">
<p>The following example creates a UltraFeedback task to emphasize honesty and uncertainty expression assessment:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="kn">import</span> <span class="nn">os</span>
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a>
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a><span class="kn">from</span> <span class="nn">distilabel.llm</span> <span class="kn">import</span> <span class="n">OpenAILLM</span>
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a><span class="kn">from</span> <span class="nn">distilabel.tasks</span> <span class="kn">import</span> <span class="n">UltraFeedbackTask</span>
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a><span class="n">labeller</span> <span class="o">=</span> <span class="n">OpenAILLM</span><span class="p">(</span>
</span><span id="__span-7-7"><a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a>    <span class="n">task</span><span class="o">=</span><span class="n">UltraFeedbackTask</span><span class="o">.</span><span class="n">for_honesty</span><span class="p">(),</span> <span class="n">openai_api_key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">)</span>
</span><span id="__span-7-8"><a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a><span class="p">)</span>
</span></code></pre></div>
</div>
<div class="tabbed-block">
<p>The following example creates a UltraFeedback task to emphasize the evaluation of alignment between output and intent:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="kn">import</span> <span class="nn">os</span>
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a>
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a><span class="kn">from</span> <span class="nn">distilabel.llm</span> <span class="kn">import</span> <span class="n">OpenAILLM</span>
</span><span id="__span-8-4"><a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a><span class="kn">from</span> <span class="nn">distilabel.tasks</span> <span class="kn">import</span> <span class="n">UltraFeedbackTask</span>
</span><span id="__span-8-5"><a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a>
</span><span id="__span-8-6"><a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a><span class="n">labeller</span> <span class="o">=</span> <span class="n">OpenAILLM</span><span class="p">(</span>
</span><span id="__span-8-7"><a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a>    <span class="n">task</span><span class="o">=</span><span class="n">UltraFeedbackTask</span><span class="o">.</span><span class="n">for_instruction_following</span><span class="p">(),</span>
</span><span id="__span-8-8"><a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>    <span class="n">openai_api_key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">),</span>
</span><span id="__span-8-9"><a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a><span class="p">)</span>
</span></code></pre></div>
</div>
</div>
</div>
<p>Additionally, we at Argilla created a custom subtask for UltraFeedback, that generates an overall score evaluating all the aspects mentioned above but within a single subtask. Otherwise, in order to get an overall score, all the subtasks above should be run and the average of those scores to be calculated.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="2:1"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio" /><div class="tabbed-labels"><label for="__tabbed_2_1">Overall Quality</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>The following example uses a <code>LLM</code> to examinate the data for our custom overall quality criteria, which includes the different criteria from UltraFeedback (Correctness &amp; Informativeness, Honesty &amp; Uncertainty, Truthfulness &amp; Hallucination and Instruction Following):</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="kn">import</span> <span class="nn">os</span>
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a>
</span><span id="__span-9-3"><a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a><span class="kn">from</span> <span class="nn">distilabel.llm</span> <span class="kn">import</span> <span class="n">OpenAILLM</span>
</span><span id="__span-9-4"><a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a><span class="kn">from</span> <span class="nn">distilabel.tasks</span> <span class="kn">import</span> <span class="n">UltraFeedbackTask</span>
</span><span id="__span-9-5"><a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a>
</span><span id="__span-9-6"><a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a><span class="n">labeller</span> <span class="o">=</span> <span class="n">OpenAILLM</span><span class="p">(</span>
</span><span id="__span-9-7"><a id="__codelineno-9-7" name="__codelineno-9-7" href="#__codelineno-9-7"></a>    <span class="n">task</span><span class="o">=</span><span class="n">UltraFeedbackTask</span><span class="o">.</span><span class="n">for_overall_quality</span><span class="p">(),</span>
</span><span id="__span-9-8"><a id="__codelineno-9-8" name="__codelineno-9-8" href="#__codelineno-9-8"></a>    <span class="n">openai_api_key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">),</span>
</span><span id="__span-9-9"><a id="__codelineno-9-9" name="__codelineno-9-9" href="#__codelineno-9-9"></a><span class="p">)</span>
</span></code></pre></div>
</div>
</div>
</div>
<p>For the API reference visit <a class="autorefs autorefs-internal" href="../../reference/distilabel/tasks/preference/ultrafeedback/#distilabel.tasks.preference.ultrafeedback.UltraFeedbackTask">UltraFeedbackTask</a>.</p>
<h4 id="judgelmtask">JudgeLMTask<a class="headerlink" href="#judgelmtask" title="Permanent link">&para;</a></h4>
<p>The task specially designed to build the prompts following the UltraFeedback paper: <a href="https://arxiv.org/abs/2310.17631">JudgeLM: Fine-tuned Large Language Models Are Scalable Judges</a>. This task is designed to evaluate the performance of AI assistants.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="kn">import</span> <span class="nn">os</span>
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a><span class="kn">from</span> <span class="nn">distilabel.llm</span> <span class="kn">import</span> <span class="n">OpenAILLM</span>
</span><span id="__span-10-4"><a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a><span class="kn">from</span> <span class="nn">distilabel.tasks</span> <span class="kn">import</span> <span class="n">JudgeLMTask</span>
</span><span id="__span-10-5"><a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a>
</span><span id="__span-10-6"><a id="__codelineno-10-6" name="__codelineno-10-6" href="#__codelineno-10-6"></a><span class="n">labeller</span> <span class="o">=</span> <span class="n">OpenAILLM</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="n">JudgeLMTask</span><span class="p">(),</span> <span class="n">openai_api_key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">))</span>
</span></code></pre></div>
<p>For the API reference visit <a class="autorefs autorefs-internal" href="../../reference/distilabel/tasks/preference/judgelm/#distilabel.tasks.preference.judgelm.JudgeLMTask">JudgeLMTask</a>.</p>
<h4 id="ultrajudgetask">UltraJudgeTask<a class="headerlink" href="#ultrajudgetask" title="Permanent link">&para;</a></h4>
<p>This class implements a <code>PreferenceTask</code> specifically for a better evaluation using AI Feedback. The task is defined based on both UltraFeedback and JudgeLM, but with several improvements / modifications.</p>
<p>It introduces an additional argument to differentiate various areas for processing. While these areas can be customized, the default values are as follows:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="kn">from</span> <span class="nn">distilabel.tasks</span> <span class="kn">import</span> <span class="n">UltraJudgeTask</span>
</span><span id="__span-11-2"><a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>
</span><span id="__span-11-3"><a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a><span class="c1"># To see the complete system_prompt and task_description please take a look at the UltraJudgeTask definition</span>
</span><span id="__span-11-4"><a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a><span class="n">ultrajudge_task</span> <span class="o">=</span> <span class="n">UltraJudgeTask</span><span class="p">(</span>
</span><span id="__span-11-5"><a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a>    <span class="n">system_prompt</span><span class="o">=</span><span class="s2">&quot;You are an evaluator tasked with assessing AI assistants&#39; responses from the perspective of typical user preferences...&quot;</span><span class="p">,</span>
</span><span id="__span-11-6"><a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a>    <span class="n">task_description</span><span class="o">=</span><span class="s2">&quot;Your task is to rigorously evaluate the performance of...&quot;</span><span class="p">,</span>
</span><span id="__span-11-7"><a id="__codelineno-11-7" name="__codelineno-11-7" href="#__codelineno-11-7"></a>    <span class="n">areas</span><span class="o">=</span><span class="p">[</span>
</span><span id="__span-11-8"><a id="__codelineno-11-8" name="__codelineno-11-8" href="#__codelineno-11-8"></a>        <span class="s2">&quot;Practical Accuracy&quot;</span><span class="p">,</span>
</span><span id="__span-11-9"><a id="__codelineno-11-9" name="__codelineno-11-9" href="#__codelineno-11-9"></a>        <span class="s2">&quot;Clarity &amp; Transparency&quot;</span><span class="p">,</span>
</span><span id="__span-11-10"><a id="__codelineno-11-10" name="__codelineno-11-10" href="#__codelineno-11-10"></a>        <span class="s2">&quot;Authenticity &amp; Reliability&quot;</span><span class="p">,</span>
</span><span id="__span-11-11"><a id="__codelineno-11-11" name="__codelineno-11-11" href="#__codelineno-11-11"></a>        <span class="s2">&quot;Compliance with Intent&quot;</span><span class="p">,</span>
</span><span id="__span-11-12"><a id="__codelineno-11-12" name="__codelineno-11-12" href="#__codelineno-11-12"></a>    <span class="p">],</span>
</span><span id="__span-11-13"><a id="__codelineno-11-13" name="__codelineno-11-13" href="#__codelineno-11-13"></a><span class="p">)</span>
</span></code></pre></div>
<p>Which can be directly used in the following way:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="kn">import</span> <span class="nn">os</span>
</span><span id="__span-12-2"><a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a>
</span><span id="__span-12-3"><a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a><span class="kn">from</span> <span class="nn">distilabel.llm</span> <span class="kn">import</span> <span class="n">OpenAILLM</span>
</span><span id="__span-12-4"><a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a><span class="kn">from</span> <span class="nn">distilabel.tasks</span> <span class="kn">import</span> <span class="n">UltraJudgeTask</span>
</span><span id="__span-12-5"><a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a>
</span><span id="__span-12-6"><a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a><span class="n">labeller</span> <span class="o">=</span> <span class="n">OpenAILLM</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="n">UltraJudgeTask</span><span class="p">(),</span> <span class="n">openai_api_key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">))</span>
</span></code></pre></div>
<p>For the API reference visit <a class="autorefs autorefs-internal" href="../../reference/distilabel/tasks/preference/ultrajudge/#distilabel.tasks.preference.ultrajudge.UltraJudgeTask">UltraJudgeTask</a>.</p>
<h4 id="complexityscorertask">ComplexityScorerTask<a class="headerlink" href="#complexityscorertask" title="Permanent link">&para;</a></h4>
<p>This class implements a <code>PreferenceTask</code> to rate a of instructions according to its complexity difficulty. Defined in <a href="https://arxiv.org/abs/2312.15685">Deita framework</a>, it's intended use is the scoring of instructions whose complexity has been enhanced by means of the <code>EvolComplexity</code> method defined, inspired on the <code>EvolInstruct</code> method from <a href="https://arxiv.org/abs/2304.12244">WizardLM</a>.  </p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-13-1"><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a><span class="kn">import</span> <span class="nn">os</span>
</span><span id="__span-13-2"><a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a>
</span><span id="__span-13-3"><a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a><span class="kn">from</span> <span class="nn">distilabel.llm</span> <span class="kn">import</span> <span class="n">OpenAILLM</span>
</span><span id="__span-13-4"><a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a><span class="kn">from</span> <span class="nn">distilabel.tasks</span> <span class="kn">import</span> <span class="n">ComplexityScorerTask</span>
</span><span id="__span-13-5"><a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a>
</span><span id="__span-13-6"><a id="__codelineno-13-6" name="__codelineno-13-6" href="#__codelineno-13-6"></a><span class="n">labeller</span> <span class="o">=</span> <span class="n">OpenAILLM</span><span class="p">(</span>
</span><span id="__span-13-7"><a id="__codelineno-13-7" name="__codelineno-13-7" href="#__codelineno-13-7"></a>    <span class="n">task</span><span class="o">=</span><span class="n">ComplexityScorerTask</span><span class="p">(),</span>
</span><span id="__span-13-8"><a id="__codelineno-13-8" name="__codelineno-13-8" href="#__codelineno-13-8"></a>    <span class="n">openai_api_key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">),</span>
</span><span id="__span-13-9"><a id="__codelineno-13-9" name="__codelineno-13-9" href="#__codelineno-13-9"></a><span class="p">)</span>
</span></code></pre></div>
<p>For the API reference visit <a class="autorefs autorefs-internal" href="../../reference/distilabel/tasks/preference/complexity_scorer/#distilabel.tasks.preference.complexity_scorer.ComplexityScorerTask">ComplexityScorerTask</a>.</p>
<h4 id="qualityscorertask">QualityScorerTask<a class="headerlink" href="#qualityscorertask" title="Permanent link">&para;</a></h4>
<p>This class implements a <code>PreferenceTask</code> to rate a list of instructions according to its quality. Follows the same idea defined in the <code>ComplexityScorerTask</code> from the <a href="https://arxiv.org/abs/2312.15685">Deita framework</a>, but in this case it rates the instructions in terms of concepts like helpfulness, relevance, accuracy, depth, creativity, and level of detail of the response.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-14-1"><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a><span class="kn">import</span> <span class="nn">os</span>
</span><span id="__span-14-2"><a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a>
</span><span id="__span-14-3"><a id="__codelineno-14-3" name="__codelineno-14-3" href="#__codelineno-14-3"></a><span class="kn">from</span> <span class="nn">distilabel.llm</span> <span class="kn">import</span> <span class="n">OpenAILLM</span>
</span><span id="__span-14-4"><a id="__codelineno-14-4" name="__codelineno-14-4" href="#__codelineno-14-4"></a><span class="kn">from</span> <span class="nn">distilabel.tasks</span> <span class="kn">import</span> <span class="n">QualityScorerTask</span>
</span><span id="__span-14-5"><a id="__codelineno-14-5" name="__codelineno-14-5" href="#__codelineno-14-5"></a>
</span><span id="__span-14-6"><a id="__codelineno-14-6" name="__codelineno-14-6" href="#__codelineno-14-6"></a><span class="n">labeller</span> <span class="o">=</span> <span class="n">OpenAILLM</span><span class="p">(</span>
</span><span id="__span-14-7"><a id="__codelineno-14-7" name="__codelineno-14-7" href="#__codelineno-14-7"></a>    <span class="n">task</span><span class="o">=</span><span class="n">QualityScorerTask</span><span class="p">(),</span>
</span><span id="__span-14-8"><a id="__codelineno-14-8" name="__codelineno-14-8" href="#__codelineno-14-8"></a>    <span class="n">openai_api_key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">),</span>
</span><span id="__span-14-9"><a id="__codelineno-14-9" name="__codelineno-14-9" href="#__codelineno-14-9"></a><span class="p">)</span>
</span></code></pre></div>
<p>By default, the quality is defined as the following the paper prompt, but can be modified updating the <code>task_description</code> as in the following example (keep in mind the default <code>task_description</code> corresponds to the <code>EvolQuality</code> criteria defined to evolve the initial instructions, so this should be taken into account):</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-15-1"><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a><span class="kn">import</span> <span class="nn">os</span>
</span><span id="__span-15-2"><a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a>
</span><span id="__span-15-3"><a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a><span class="kn">from</span> <span class="nn">distilabel.llm</span> <span class="kn">import</span> <span class="n">OpenAILLM</span>
</span><span id="__span-15-4"><a id="__codelineno-15-4" name="__codelineno-15-4" href="#__codelineno-15-4"></a><span class="kn">from</span> <span class="nn">distilabel.tasks</span> <span class="kn">import</span> <span class="n">QualityScorerTask</span>
</span><span id="__span-15-5"><a id="__codelineno-15-5" name="__codelineno-15-5" href="#__codelineno-15-5"></a>
</span><span id="__span-15-6"><a id="__codelineno-15-6" name="__codelineno-15-6" href="#__codelineno-15-6"></a><span class="n">labeller</span> <span class="o">=</span> <span class="n">OpenAILLM</span><span class="p">(</span>
</span><span id="__span-15-7"><a id="__codelineno-15-7" name="__codelineno-15-7" href="#__codelineno-15-7"></a>    <span class="n">task</span><span class="o">=</span><span class="n">QualityScorerTask</span><span class="p">(</span><span class="n">task_description</span><span class="o">=</span><span class="s2">&quot;Take into account the expressiveness of the answers.&quot;</span><span class="p">),</span>
</span><span id="__span-15-8"><a id="__codelineno-15-8" name="__codelineno-15-8" href="#__codelineno-15-8"></a>    <span class="n">openai_api_key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">),</span>
</span><span id="__span-15-9"><a id="__codelineno-15-9" name="__codelineno-15-9" href="#__codelineno-15-9"></a><span class="p">)</span>
</span></code></pre></div>
<p>For the API reference visit <a class="autorefs autorefs-internal" href="../../reference/distilabel/tasks/preference/quality_scorer/#distilabel.tasks.preference.quality_scorer.QualityScorerTask">QualityScorerTask</a>.</p>
<h3 id="critique">Critique<a class="headerlink" href="#critique" title="Permanent link">&para;</a></h3>
<p>The <code>CritiqueTask</code> is designed to be a labeller for generated text, while not only adding scores based on a rubric, but also critiques explaining the reasons why those scores have been provided. The critique can either be using a reference answer (gold answer) as e.g. Prometheus does, or just by generating the critique per each of the N provided generations.</p>
<p>The resulting datasets after running a pipeline with the <code>CritiqueTask</code> are useful towards either training a model to generate critiques based on the critiques generated by a more powerful model as e.g. GPT-4 from OpenAI, or to be used directly for DPO fine-tuning. The fact that the critique is generated per each pair, a balanced dataset could be generated with individual critiques and their scores, so that then we can e.g. define a threshold on what's considered chosen and rejected, to then run DPO fine-tunes.</p>
<p>While the <code>CritiqueTask</code> may seem fairly similar to the <code>PreferenceTask</code>, there is a core difference, which is the fact that the critiques are provided per each response or even to a single response, with no need to compare or rate them against each other.</p>
<h4 id="ultracmtask">UltraCMTask<a class="headerlink" href="#ultracmtask" title="Permanent link">&para;</a></h4>
<p>This task is specifically designed to build the prompts following the format defined in the <a href="https://arxiv.org/abs/2310.01377">"UltraFeedback: Boosting Language Models With High Quality Feedback"</a> paper.</p>
<p>UltraCM is a model that has been fine-tuned using the UltraFeedback dataset, so as to produce critiques for the generated content, as the authors claim in their paper: "Moreover, since ULTRAFEEDBACK provides detailed textual feedback, we also fine-tune a model that could critique model responses automatically. Our critique model, UltraCM, generates reasonable and detailed comments on various tasks.".</p>
<p>Ideally, the <code>UltraCMTask</code> will be more consistent when used with either their fine-tuned model UltraCM or with OpenAI, as both have been proven to produce successfully the structured content following the prompt formatting, and not only structured, but also meaningful and reasonable.</p>
<p>See the following snippet, with an example on how to instantiate the <code>UltraCMTask</code> which only requires the system prompt, and it can be modified based on how is the critique intended to be formulated, while the system prompt shown below is the default one as of the UltraFeedback paper.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-16-1"><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a><span class="kn">from</span> <span class="nn">distilabel.tasks</span> <span class="kn">import</span> <span class="n">UltraCMTask</span>
</span><span id="__span-16-2"><a id="__codelineno-16-2" name="__codelineno-16-2" href="#__codelineno-16-2"></a>
</span><span id="__span-16-3"><a id="__codelineno-16-3" name="__codelineno-16-3" href="#__codelineno-16-3"></a><span class="n">task</span> <span class="o">=</span> <span class="n">UltraCMTask</span><span class="p">(</span>
</span><span id="__span-16-4"><a id="__codelineno-16-4" name="__codelineno-16-4" href="#__codelineno-16-4"></a>    <span class="n">system_prompt</span><span class="o">=</span><span class="s2">&quot;User: A one-turn chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, very detailed, and polite answers to the user&#39;s questions.&lt;/s&gt;&quot;</span><span class="p">,</span>
</span><span id="__span-16-5"><a id="__codelineno-16-5" name="__codelineno-16-5" href="#__codelineno-16-5"></a><span class="p">)</span>
</span></code></pre></div>
<h4 id="prometheustask">PrometheusTask<a class="headerlink" href="#prometheustask" title="Permanent link">&para;</a></h4>
<p>This task is specifically designed to build the prompts following the format defined in the <a href="https://arxiv.org/abs/2310.08491">"Prometheus: Inducing Fine-grained Evaluation Capability in Language Models"</a> paper.</p>
<p>Ideally, the <code>PrometheusTask</code> should only be used to format the prompts for the Prometheus models as those are the ones that have been fine-tuned to follow the same formatting and will produce consistent results compared to other base models or fine-tuned with different formats. In this case, since the formatting used by Prometheus follows the Llama 2 format, those are recommended. Otherwise, OpenAI has also proved to produce consistent results.</p>
<p>The following snippet can be used out of the box to define a simple <code>PrometheusTask</code> with the system prompt, the scoring criteria and the score descriptions, but those can be modified while keeping in mind that Prometheus always expects 5 scores from 1-5 with a meaningful description, as well as with a criteria relevant to the scores defined.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-17-1"><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a><span class="kn">from</span> <span class="nn">distilabel.tasks</span> <span class="kn">import</span> <span class="n">PrometheusTask</span>
</span><span id="__span-17-2"><a id="__codelineno-17-2" name="__codelineno-17-2" href="#__codelineno-17-2"></a>
</span><span id="__span-17-3"><a id="__codelineno-17-3" name="__codelineno-17-3" href="#__codelineno-17-3"></a><span class="n">task</span> <span class="o">=</span> <span class="n">PrometheusTask</span><span class="p">(</span>
</span><span id="__span-17-4"><a id="__codelineno-17-4" name="__codelineno-17-4" href="#__codelineno-17-4"></a>    <span class="n">system_prompt</span><span class="o">=</span><span class="s2">&quot;You are a fair evaluator language model.&quot;</span><span class="p">,</span>
</span><span id="__span-17-5"><a id="__codelineno-17-5" name="__codelineno-17-5" href="#__codelineno-17-5"></a>    <span class="n">scoring_criteria</span><span class="o">=</span><span class="s2">&quot;Relevance, Grammar, Informativeness, Engagement&quot;</span><span class="p">,</span>
</span><span id="__span-17-6"><a id="__codelineno-17-6" name="__codelineno-17-6" href="#__codelineno-17-6"></a>    <span class="n">score_descriptions</span><span class="o">=</span><span class="p">{</span>
</span><span id="__span-17-7"><a id="__codelineno-17-7" name="__codelineno-17-7" href="#__codelineno-17-7"></a>        <span class="mi">1</span><span class="p">:</span> <span class="s2">&quot;The response is not relevant to the prompt.&quot;</span><span class="p">,</span>
</span><span id="__span-17-8"><a id="__codelineno-17-8" name="__codelineno-17-8" href="#__codelineno-17-8"></a>        <span class="mi">2</span><span class="p">:</span> <span class="s2">&quot;The response is relevant to the prompt, but it is not grammatical.&quot;</span><span class="p">,</span>
</span><span id="__span-17-9"><a id="__codelineno-17-9" name="__codelineno-17-9" href="#__codelineno-17-9"></a>        <span class="mi">3</span><span class="p">:</span> <span class="s2">&quot;The response is relevant to the prompt and it is grammatical, but it is not informative.&quot;</span><span class="p">,</span>
</span><span id="__span-17-10"><a id="__codelineno-17-10" name="__codelineno-17-10" href="#__codelineno-17-10"></a>        <span class="mi">4</span><span class="p">:</span> <span class="s2">&quot;The response is relevant to the prompt, it is grammatical, and it is informative, but it is not engaging.&quot;</span><span class="p">,</span>
</span><span id="__span-17-11"><a id="__codelineno-17-11" name="__codelineno-17-11" href="#__codelineno-17-11"></a>        <span class="mi">5</span><span class="p">:</span> <span class="s2">&quot;The response is relevant to the prompt, it is grammatical, it is informative, and it is engaging.&quot;</span><span class="p">,</span>
</span><span id="__span-17-12"><a id="__codelineno-17-12" name="__codelineno-17-12" href="#__codelineno-17-12"></a>    <span class="p">},</span>
</span><span id="__span-17-13"><a id="__codelineno-17-13" name="__codelineno-17-13" href="#__codelineno-17-13"></a><span class="p">)</span>
</span></code></pre></div>
<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p>The principles can be found <a class="autorefs autorefs-internal" href="../../reference/distilabel/tasks/text_generation/principles/#distilabel.tasks.text_generation.principles">here</a> in the codebase. More information on the <em>Principle Sampling</em> can be found in the <a href="https://github.com/OpenBMB/UltraFeedback#principle-sampling">UltraFeedfack repository</a>.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>







  
  






                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "navigation.tabs", "toc.follow", "content.code.copy", "content.code.annotate"], "search": "../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.e1c3ead8.min.js"></script>
      
    
  </body>
</html>